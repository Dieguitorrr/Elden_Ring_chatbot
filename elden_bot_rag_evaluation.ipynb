{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7db2b1-8f9c-46bd-9c50-b6cfb0a38a22",
   "metadata": {},
   "source": [
    "## RAG Evaluation with Langsmith\n",
    "\n",
    "For this evaluation we will be using 3 different types of RAG evaluation (here, `<>` means \"compared against\"):\n",
    "\n",
    "1. **Response <> reference answer**: We will measure \"*how similar/correct is the answer, relative to a ground-truth*\"\n",
    "2. **Response <> input**: metrics like answer relevance, helpfulness, etc. measure \"*how well does the generated response address the initial user input*\"\n",
    "3. **Response <> retrieved docs**: metrics like faithfulness, hallucinations, etc. measure \"*to what extent does the generated response agree with the retrieved context*\"\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"https://education-team-2020.s3.eu-west-1.amazonaws.com/ai-eng/langsmith_rag_eval.png\" alt='langsmith_rag_eval' width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "### Step 1: Create the RAG pipeline \n",
    "\n",
    "We will be using LangChain strictly for creating the retriever and retrieving the relevant documents. The overall pipeline does not use LangChain. LangSmith works regardless of whether or not your pipeline is built with LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d809e9a0-44bc-4e9f-8eee-732ef077538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %capture --no-stderr\n",
    "# ! pip install langsmith langchain-community langchain chromadb tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4841d17a",
   "metadata": {},
   "source": [
    "First the imports and API keys needed to make the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c19813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegoalonso/Documents/elden_ring_chatbot _FINAL/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langsmith import Client\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langsmith.evaluation import evaluate\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e97fcce-136a-484d-a3da-933c1edc1583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:35:38.080837Z",
     "start_time": "2024-10-26T14:35:38.068635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "LANGCHAIN_TRACING_V2=True\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_PROJECT=\"elden_ring_chatbot\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760cab79-2d5e-4324-ba4a-54b6f4094cb0",
   "metadata": {},
   "source": [
    "We build the index using the existing Vector Database created with Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c0017-f4dd-4071-aa48-40957ffb4e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:36:42.854166Z",
     "start_time": "2024-10-26T14:36:29.164126Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dy/909n7xmj5_70npk7nknw102m0000gn/T/ipykernel_21555/1379878443.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(\n",
      "/Users/diegoalonso/Documents/elden_ring_chatbot _FINAL/.venv/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing vector store.\n"
     ]
    }
   ],
   "source": [
    "# INDEX\n",
    "\n",
    "# Initialize the embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Path to the vector store directory\n",
    "persist_directory = \"Elden_vector_store\"\n",
    "collection_name = \"Elden_Ring_Lore\"\n",
    "\n",
    "# Load the existing vector store\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name=collection_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8cf89",
   "metadata": {},
   "source": [
    "Create the retriever (the same that we used for the chatbot to keep consistent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5807c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the retriever\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365fb82-78a6-40b6-bd59-daaa1e79d6c8",
   "metadata": {},
   "source": [
    "Next, we build a `RAG chain` that returns an `answer` and the retrieved documents as `contexts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e249d7-bc6c-4631-b099-6daaeeddf38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:38:06.938420Z",
     "start_time": "2024-10-26T14:38:06.916654Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### RAG\n",
    "\n",
    "class RagBot:\n",
    "    def __init__(self, retriever, model: str = \"gpt-4-0125-preview\"):\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        self._client = wrap_openai(openai.Client())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        similar = self.retrieve_docs(question)\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"\"\"You are a lore master of Elden Ring, entrusted to narrate only the stories of the game's world. \n",
    "                    Speak in an epic tone as if revealing ancient knowledge but remain precise and truthful providing guidence for the adventurer.\n",
    "\n",
    "                    Question:\n",
    "                    {question}\n",
    "\n",
    "                    Answer:.\"\"\"\n",
    "                \n",
    "                    f\"## Docs\\n\\n{similar}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluators will expect \"answer\" and \"contexts\"\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in similar],\n",
    "        }\n",
    "\n",
    "\n",
    "rag_bot = RagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6101d155-a1ab-460c-8c3e-f1f44e09a8b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:38:22.113590Z",
     "start_time": "2024-10-26T14:38:17.196185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the era shadowed by the aftershocks of the Shattering, the lands Between are roiled by the sagas of the demigods, offspring of Queen Marika the Ete'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_bot.get_answer(\"Who are the demigods?\")\n",
    "response[\"answer\"][:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e8ec7-a085-4224-ad38-0087e1d553f1",
   "metadata": {},
   "source": [
    "### Step 2: Build up the RAG Dataset \n",
    "\n",
    "Next, we build a dataset of QA pairs based upon the documentation that we indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f29304f-d79b-40e9-988a-343732102af9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:39:14.390481Z",
     "start_time": "2024-10-26T14:39:13.365484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA dataset for Elden Ring Game created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Sample \n",
    "# Pairs extracted for Elden Ring\n",
    "inputs = [\n",
    "    \"What is the Greater Will and how did it shape the Lands Between?\",\n",
    "    \"Who are the Two Fingers and what role do they play in the Golden Order?\",\n",
    "    \"What is the significance of the Rune of Death in Elden Ring's lore?\",\n",
    "    \"Who is Queen Marika and how did she change the fate of the Lands Between?\",\n",
    "    \"What is the origin of the Erdtree and why is it important?\",\n",
    "    \"Who is Radagon, and what connection does he have with Queen Marika?\",\n",
    "    \"What are the Outer Gods, and how do they influence the world of Elden Ring?\",\n",
    "    \"What role does the Tarnished play in the grand scheme of the Elden Ring story?\"\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"The Greater Will is an Outer God that sent the Elden Beast to the Lands Between, establishing the Golden Order and shaping the world according to its divine plan. Its influence is seen in the governance and faith of the Lands Between.\",\n",
    "    \"The Two Fingers serve as envoys of the Greater Will, interpreting its desires and guiding the inhabitants of the Lands Between to maintain the Golden Order. They communicate through Finger Readers and help chosen Tarnished understand their destiny.\",\n",
    "    \"The Rune of Death, once part of the Elden Ring, was removed by Queen Marika to prevent the true death of beings. This act created the foundation for the Golden Order, allowing the Erdtree to reabsorb the souls of the deceased and prevent their permanent demise.\",\n",
    "    \"Queen Marika is the Empyrean chosen by the Greater Will to embody the Elden Ring. Her decisions, including removing the Rune of Death and shattering the Elden Ring, triggered significant upheavals that set the stage for the gameâ€™s events.\",\n",
    "    \"The Erdtree, believed to be a manifestation of the Greater Will's power, stands as a beacon of order and life in the Lands Between. Its roots connect to the fundamental flow of souls and the Golden Order, symbolizing divine grace.\",\n",
    "    \"Radagon is a mysterious figure who is both the consort of Queen Rennala and later revealed to be part of Queen Marika herself. His dual identity is key to understanding the complex narrative surrounding the Elden Ring's shattering.\",\n",
    "    \"The Outer Gods are powerful entities like the Greater Will, the Frenzied Flame, and the Formless Mother. They exert their influence over the Lands Between, often conflicting with one another and affecting the fate of its inhabitants.\",\n",
    "    \"The Tarnished are exiled beings called back to the Lands Between to reclaim their grace and pursue the path to becoming the Elden Lord. Their role is to mend the Elden Ring and bring order or chaos, depending on their choices.\"\n",
    "]\n",
    "\n",
    "# Create the QA pairs\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "\n",
    "# Initialize the LangSmith client\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Elden_Ring_evaluation_3\"\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"QA pairs focusing on Elden Ring gameplay, lore, characters, and strategies.\"\n",
    ")\n",
    "\n",
    "# Add examples to the dataset\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],\n",
    "    outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "print(\"QA dataset for Elden Ring Game created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf3a0f-621f-468d-818d-a6f2d4b53823",
   "metadata": {},
   "source": [
    "## Langsmith RAG Evaluators\n",
    "\n",
    "### Type 1: Answer accuracy\n",
    "\n",
    "First, lets consider the case in which we want to compare our RAG chain answer to a reference answer.\n",
    "\n",
    "\n",
    "#### Evaluation flow\n",
    "\n",
    "We will use an LLM as judge with an customized grader prompt: \n",
    "\n",
    "https://smith.langchain.com/hub/langchain-ai/rag-answer-vs-reference\n",
    "\n",
    "![langsmith_rag_flow.png](images/langsmith_rag_flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbe0b4a-2a30-4f40-b3aa-5cc67c6a7802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:41:18.013066Z",
     "start_time": "2024-10-26T14:41:18.002261Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RAG chain evaluation for Elden Ring-specific questions\n",
    "def predict_rag_answer(example: dict):\n",
    "    \"\"\"\n",
    "    Use this function to predict answers to questions related to Elden Ring's lore,\n",
    "    characters, mechanics, or gameplay for evaluation purposes.\n",
    "    \"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\"answer\": response[\"answer\"]}\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"\n",
    "    Use this function for detailed evaluation, including retrieved context and checking for hallucinations.\n",
    "    This is especially useful for verifying if the response includes relevant Elden Ring context.\n",
    "    \"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\n",
    "        \"answer\": response[\"answer\"],\n",
    "        \"contexts\": response[\"contexts\"] \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52104cef-d711-4b3f-a37f-7b887213fdd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:41:20.007038Z",
     "start_time": "2024-10-26T14:41:19.470736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grade prompt for answer accuracy, ensure the prompt aligns with Elden Ring's content.\n",
    "grade_prompt_answer_accuracy = prompt = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer accuracy.\n",
    "    \"\"\"\n",
    "    input_question = example.inputs[\"question\"]\n",
    "    reference = example.outputs[\"answer\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "    # Create a formatted input as a string\n",
    "    prompt_input = (\n",
    "        f\"Evaluate the student's answer based on its accuracy:\\n\"\n",
    "        f\"Question: {input_question}\\n\"\n",
    "        f\"Correct Answer: {reference}\\n\"\n",
    "        f\"Student Answer: {prediction}\\n\"\n",
    "        f\"Provide a numerical score between 0 and 100 based on accuracy.\\n\"\n",
    "        f\"Output the score in the following format: 'Accuracy Score: [number]'.\"\n",
    "    )\n",
    "\n",
    "    # Use HumanMessage for structured input\n",
    "    response = llm.invoke([HumanMessage(content=prompt_input)])\n",
    "    score_content = response.content  # Access the generated response text\n",
    "\n",
    "    # Extract the score using a refined regex pattern\n",
    "    match = re.search(r'Accuracy Score:\\s*(\\d+)', score_content)\n",
    "    if match:\n",
    "        score = int(match.group(1))  # Extract the score after 'Accuracy Score:'\n",
    "    else:\n",
    "        raise ValueError(\"Score could not be extracted from LLM response.\")\n",
    "\n",
    "    print(f'question={input_question}, score={score}')\n",
    "    return {\"key\": \"answer_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920b39ac-ff96-404e-ab92-87425f0419d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:42:11.371779Z",
     "start_time": "2024-10-26T14:41:48.079343Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'elde_bot_rag_accuracy_3-5d12a156' at:\n",
      "https://smith.langchain.com/o/8149cca6-21e4-4567-9557-d316bd677644/datasets/c1f83cf2-8ed7-4b15-ab0b-5e5d5b6b1c50/compare?selectedSessions=4606558e-13d2-4a90-827a-0e6619520238\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/dy/909n7xmj5_70npk7nknw102m0000gn/T/ipykernel_21555/3277913846.py:12: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What is the origin of the Erdtree and why is it important?, score=85\n",
      "question=Who are the Two Fingers and what role do they play in the Golden Order?, score=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:18,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What role does the Tarnished play in the grand scheme of the Elden Ring story?, score=95\n",
      "question=What are the Outer Gods, and how do they influence the world of Elden Ring?, score=85\n",
      "question=Who is Radagon, and what connection does he have with Queen Marika?, score=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:22,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What is the significance of the Rune of Death in Elden Ring's lore?, score=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:24,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What is the Greater Will and how did it shape the Lands Between?, score=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:25,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=Who is Queen Marika and how did she change the fate of the Lands Between?, score=85\n",
      "Evaluation complete. Results are stored in the experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure the dataset name matches your Elden Ring-specific dataset\n",
    "dataset_name = \"Elden_Ring_evaluation_3\"\n",
    "\n",
    "# Run the evaluation experiment\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_evaluator],\n",
    "    experiment_prefix=\"elde_bot_rag_accuracy_3\",\n",
    "    metadata={\"variant\": \"Elden Ring context, gpt-3.5-turbo\"},\n",
    ")\n",
    "\n",
    "print(\"Evaluation complete. Results are stored in the experiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba4123-c691-4aa0-ba76-e567e8aaf09f",
   "metadata": {},
   "source": [
    "### Type 2: Answer Hallucination\n",
    "\n",
    "#### Eval flow\n",
    "\n",
    "We simply use an LLM-as-judge with an easily customized grader prompt: \n",
    "\n",
    "https://smith.langchain.com/hub/langchain-ai/rag-answer-hallucination\n",
    "\n",
    "![langsmith_rag_flow_hallucination.png](images/langsmith_rag_flow_hallucination.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19f8818-9e5e-496c-8a75-b5065113ca70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:44:11.480027Z",
     "start_time": "2024-10-26T14:44:10.955557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pull the prompt for evaluating hallucinations\n",
    "grade_prompt_hallucinations = hub.pull(\"langchain-ai/rag-answer-hallucination\")\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluator for detecting hallucinations in answers related to Elden Ring.\n",
    "    \"\"\"\n",
    "    input_question = example.inputs[\"question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "    # Create prompt for hallucination evaluation\n",
    "    prompt_input = (\n",
    "        f\"Evaluate if the student's answer is fully supported by the provided documents:\\n\"\n",
    "        f\"Question: {input_question}\\n\"\n",
    "        f\"Student Answer: {prediction}\\n\"\n",
    "        f\"Relevant Contexts:\\n{contexts}\\n\"\n",
    "        f\"Indicate whether the answer includes hallucinations or unsupported content and provide a score below are the specifications:\\n\"\n",
    "        f\"- hallucination or unsupported content = 1: hallucination detected\\n\"\n",
    "        f\"- hallucination or unsupported content = 0: no hallucination detected\\n\"\n",
    "        f\"- Score: 0 for a bad answer, 3 for an okay answer, 5 for an excellent answer\\n\"\n",
    "        f\"Format your response as: 'Hallucination: [0 or 1], Score: [0, 3, or 5]'.\"\n",
    "    )\n",
    "\n",
    "    # Invoke LLM and parse response\n",
    "    response = llm.invoke([HumanMessage(content=prompt_input)])\n",
    "    hallucination_content = response.content\n",
    "\n",
    "    # Extract hallucination and score using regex\n",
    "    match = re.search(r'Hallucination:\\s*(\\d),\\s*Score:\\s*(\\d)', hallucination_content)\n",
    "    if match:\n",
    "        hallucination_flag = int(match.group(1))\n",
    "        score = int(match.group(2))\n",
    "    else:\n",
    "        raise ValueError(\"Hallucination or score could not be extracted from LLM response.\")\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"hallucination\": hallucination_flag, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9d2404f-af24-4f0b-9dab-95e3db8b0db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:44:39.296034Z",
     "start_time": "2024-10-26T14:44:13.740257Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'elden_bot_rag_hallucination_3-50809ead' at:\n",
      "https://smith.langchain.com/o/8149cca6-21e4-4567-9557-d316bd677644/datasets/c1f83cf2-8ed7-4b15-ab0b-5e5d5b6b1c50/compare?selectedSessions=06f2256e-e001-47ac-83fe-4301ed33d1a1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:32,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for Elden Ring answer hallucination detection completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Elden_Ring_evaluation_3\"\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_hallucination_evaluator],\n",
    "    experiment_prefix=\"elden_bot_rag_hallucination_3\",\n",
    "    metadata={\n",
    "        \"variant\": \"Elden Ring context, gpt-3.5-turbo\",  # Adjust as needed for model specificity\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Evaluation for Elden Ring answer hallucination detection completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a27cb-1a31-4194-b160-8cdcfbf24eea",
   "metadata": {},
   "source": [
    "### Type 3: Document Relevance to Question\n",
    "\n",
    "#### Eval flow\n",
    "\n",
    "We simply use an LLM-as-judge with an easily customized grader prompt: \n",
    "\n",
    "https://smith.langchain.com/hub/langchain-ai/rag-document-relevance\n",
    "\n",
    "![langsmith_rag_flow_doc_relevance.png](images/langsmith_rag_flow_doc_relevance.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e7e1ad-3e86-461f-aea7-67cbc86c3dca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:47:05.010254Z",
     "start_time": "2024-10-26T14:47:04.489132Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pull the document relevance grading prompt\n",
    "grade_prompt_doc_relevance = hub.pull(\"langchain-ai/rag-document-relevance\")\n",
    "\n",
    "def docs_relevance_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluator for checking document relevance for Elden Ring questions and context.\n",
    "    \"\"\"\n",
    "    input_question = example.inputs[\"question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "    # Create a formatted prompt for document relevance evaluation\n",
    "    prompt_input = (\n",
    "        f\"Evaluate the relevance of the provided documents for the given question:\\n\"\n",
    "        f\"Question: {input_question}\\n\"\n",
    "        f\"Documents:\\n{contexts}\\n\"\n",
    "        f\"Student Answer: {prediction}\\n\"\n",
    "        f\"Provide a score between 0 and 100 for how relevant the documents are to the question and answer.\"\n",
    "        f\" Format your response as: 'Score: [number]'.\"\n",
    "    )\n",
    "\n",
    "    # Use HumanMessage for structured input\n",
    "    response = llm.invoke([HumanMessage(content=prompt_input)])\n",
    "    relevance_content = response.content  # Access the response text\n",
    "\n",
    "    # Extract the score using regex or interpret response as needed\n",
    "    match = re.search(r'Score:\\s*(\\d+)', relevance_content)\n",
    "    if match:\n",
    "        score = int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(\"Relevance score could not be extracted from LLM response.\")\n",
    "\n",
    "    print(f'question={input_question}, score={score}')\n",
    "    return {\"key\": \"document_relevance\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6657472-eaa4-4e3a-80f7-5f6287e0e0f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T14:47:35.024932Z",
     "start_time": "2024-10-26T14:47:05.973023Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'elden_bot_rag_relevance_3-1da035a5' at:\n",
      "https://smith.langchain.com/o/8149cca6-21e4-4567-9557-d316bd677644/datasets/c1f83cf2-8ed7-4b15-ab0b-5e5d5b6b1c50/compare?selectedSessions=91eb8a2d-e994-406d-bc85-6f3682674ab0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=Who are the Two Fingers and what role do they play in the Golden Order?, score=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:17, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What are the Outer Gods, and how do they influence the world of Elden Ring?, score=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:18,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=Who is Radagon, and what connection does he have with Queen Marika?, score=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:19,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What is the Greater Will and how did it shape the Lands Between?, score=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:20,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What is the significance of the Rune of Death in Elden Ring's lore?, score=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:21,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=What is the origin of the Erdtree and why is it important?, score=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:24,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=Who is Queen Marika and how did she change the fate of the Lands Between?, score=85\n",
      "question=What role does the Tarnished play in the grand scheme of the Elden Ring story?, score=0\n",
      "Document relevance evaluation for Elden Ring completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Elden_Ring_evaluation_3\"\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context,\n",
    "    data=dataset_name,\n",
    "    evaluators=[docs_relevance_evaluator],\n",
    "    experiment_prefix=\"elden_bot_rag_relevance_3\",\n",
    "    metadata={\n",
    "        \"variant\": \"Elden Ring context, gpt-3.5-turbo\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Document relevance evaluation for Elden Ring completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c9f06b891d5ef",
   "metadata": {},
   "source": [
    "You can find more Langsmith evaluation tutorials in the [official documentation](https://docs.smith.langchain.com/evaluation/tutorials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
